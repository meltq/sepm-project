{
    "name": "text-tokenizer",
    "deps": [
        "lazy_static",
        "regex",
        "unicode-segmentation",
        "unicode_categories"
    ]
}