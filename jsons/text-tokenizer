{
    "name": "text-tokenizer",
    "vers": "0.4.1",
    "deps": [
        {
            "name": "lazy_static",
            "req": "^1.1",
            "features": [],
            "optional": false,
            "default_features": true,
            "target": null,
            "kind": "normal"
        },
        {
            "name": "regex",
            "req": "^1",
            "features": [],
            "optional": false,
            "default_features": true,
            "target": null,
            "kind": "normal"
        },
        {
            "name": "unicode-segmentation",
            "req": "^1.2",
            "features": [],
            "optional": false,
            "default_features": true,
            "target": null,
            "kind": "normal"
        },
        {
            "name": "unicode_categories",
            "req": "^0.1",
            "features": [],
            "optional": false,
            "default_features": true,
            "target": null,
            "kind": "normal"
        }
    ],
    "cksum": "bb696b99716f53e8ba09ccbe476a3eee324cc9b9b9227efa6e163b987e760cd2",
    "features": {
        "default": [
            "strings"
        ],
        "strings": []
    },
    "yanked": false
}